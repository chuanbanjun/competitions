## HAN
使用分层注意力机制 HAN + 多任务学习 解决 AI Challenger 细粒度用户评论情感分析 。https://challenger.ai/competition/fsauor2018

## 问题分析
具体问题描述：https://challenger.ai/competition/fsauor2018

看到题目后对问题和数据做了一些探索分析：

### 问题定义：多分类问题、多标签分类、多任务学习

* 多分类问题

	每个小类都需要分成 正向、中性、负向、未提及 四种情感，所以其首先是个多分类问题。
	
* 多标签问题

	站在样本角度看，每一个样本被打上了 20 个不同类别的情感标签，所以其也是一个多标签分类问题。
	
* 多任务学习

	问题需要对 6大类20个小类 的细粒度要素情感倾向进行预测，发现每个大类下面的小类之间是相互有联系，并不是完全独立的，比如：大类 位置 下有 交通是否便利、距离商圈远近、是否容易寻找。所以使用迁移学习中的多任务学习或许可以改善分类效果。
	
### 数据的一些主要发现：

某些类别的四种情感标签分布特别不均衡；最后一个大类 其他（本次消费感受、再次消费意愿），是对整体感受的描述，前边各个类评价正向的话，直觉这里也将会有更大概率正向。通过对样本数据统计分析后发现确实如此。

## 方案

对于多标签问题，最一般的做法会把每一个类别标签训练一个分类器，好处是简单好理解，弊端是训练时间长，忽略了不同类别标签间的联系，更大量的类别标签无法处理，比如几百上千的类别标签就需要训练几百上千个模型，显然是不可能的。

多任务学习，多个有联系的任务在特征提取阶段共享参数，只在最后几层单独做区分和输出。优点是考虑了不同任务间的联系，有联系的类别标签可以一块训练，对不均衡的样本数据有增强作用。

seq2seq，最新的研究把多标签的预测问题看成了一个序列到序列的学习，这样既考虑了标签之间的联系，又可以处理大量标签的问题，很新颖的思路。Rank 4 的选手就是使用了这种方法，很厉害。

我看到这个比赛的时候，正好刚看了 分层注意力机制 和 多任务的一些 论文，所以就想在这个问题上实现一下。

## 代码

attention_layer.py 注意力机制实现

han_model.py 分层注意力机制 + 多任务学习实现

data_factory.py 数据工厂类

utils.py 工具类

prepare.py 数据预处理

train.py 训练

predict.py 预测

evaluate.py 评估

---

config.py 配置文件

main.py 主程序

## 调试运行

调参和运行时，只需要 修改 config.py 里的值，然后运行 main.py 即可完成训练、预测、评估 整个流程。

## ToDo

* 尝试将 share 层提前到句级别

* 保存每个小类 loss 最小的 model

* Embedding 层 concat word 和 char 级别，增加多样性，缓解 OOV

* 使用 Transformer 作特征提取器

* 对样本多采样或者欠采样，或者更改目标损失函数来处理样本不均衡的问题

* 试试 ELMo









	